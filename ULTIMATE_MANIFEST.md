# jusDNCE // ULTIMATE SYSTEM MANIFEST & SOURCE OF TRUTH

**Version:** 2.5 (Mechanical Rigid Body & Hard Cut Architecture)
**Date:** Current Build
**Status:** Production Ready

---

## 1. THE CORE: AI GENERATION PIPELINE (`services/gemini.ts`)

This is the "Factory" that creates the raw assets. We moved from "Artistic Interpretation" to **"Mechanical Grid Enforcement"** to solve the drifting limb problem.

### 1.1 Input Normalization
**Function:** `resizeImage(file, 384)`
*   **Logic:** We proactively downscale user uploads to a max dimension of `384px`.
*   **Why:**
    1.  **Cost:** 384px consumes significantly fewer tokens than 1024px.
    2.  **Context:** The AI doesn't need 4K resolution to understand "This is a guy in a hoodie."
    3.  **Speed:** Faster upload and processing times.

### 1.2 The "Mechanical" Prompt Strategy
**Function:** `generateSingleSheet`
*   **The Pivot:** We stopped asking for "A sprite sheet of a dancer" and started asking for "A strict 4x4 Grid with Centroid Alignment."
*   **Key Instructions:**
    *   *"Scale to 75%"*: This creates a mathematical safety buffer (12.5% padding on all sides). Even if the AI drifts, the character remains inside the cell.
    *   *"Center of mass in middle of cell"*: Forces the model to anchor the subject, preventing them from walking off the edge.
*   **Visual Reference:** We pass the generated `base` sheet as a context image to `alt`, `flourish`, and `smooth` sheets to ensure the character wears the same clothes across all generations.

### 1.3 The Slicer & Mirror Engine
**Function:** `sliceSpriteSheet` & `mirrorFrame`
*   **Normalization:** We draw the raw base64 output onto a `1024x1024` canvas. This forces a standard coordinate system regardless of the input aspect ratio.
*   **The Cut:** We slice exactly at `25%` intervals (0, 256, 512, 768).
*   **The "Safety Crop":** We apply a `0.10` (10%) inner crop to each cell. This shaves off the grid lines generated by the AI but leaves the character intact (thanks to the 75% scale rule).
*   **Mirroring:** To save tokens, we often generate one direction (e.g., "Step Left") and programmatically flip the canvas to create "Step Right." This doubles our effective frame count for zero API cost.

---

## 2. THE BRAIN: CHOREOGRAPHY & AUDIO (`components/Step4Preview.tsx`)

This is the runtime engine. It connects the music to the visuals.

### 2.1 Audio Analysis
**Ref:** `analyserRef`, `loop()`
*   **FFT Size:** 256 (Small, fast, snappy).
*   **Frequency Bands:**
    *   **Bass (0-5):** The Kick. Drives the physics engine and pose switching.
    *   **Mid (5-30):** The Snare. Drives the "Stutter" and "Glitch" effects.
    *   **High (30-100):** Vocals/Hi-Hats. Drives facial closeups (`morph` transitions) and sparkle shaders.

### 2.2 The Rhythm State Machine
**Ref:** `framesByEnergy`
*   **Bucketing:** Frames are sorted into `low`, `mid`, `high`, and `closeup` buckets based on their metadata from `gemini.ts`.
*   **The "Hard Cut" Pivot:**
    *   *Previous:* We interpolated everything. Fast beats looked like a blurry mess.
    *   *Current:* We use **Rhythm Gating**.
        *   `if (bass > 0.6)` -> Immediate **HARD CUT** to a new pose.
        *   This creates the "Stop-Motion" / "TikTok" aesthetic that feels much tighter.

### 2.3 Interpolation Logic
**Function:** `triggerTransition`
*   **Mode 'CUT':** Duration ~0ms. Used for body moves on the beat.
*   **Mode 'MORPH':** Duration ~200ms. **Only** used when transitioning to/from a `closeup` (Face). This makes the face "melt" out of the body for a dramatic effect, while the dancing remains snappy.

---

## 3. THE BODY: PHYSICS & COMPOSITING (`Step4Preview.tsx`)

We don't just display images; we simulate a physical camera and character rig.

### 3.1 Spring Mass System
**Ref:** `masterRotX`, `camZoom`
*   **Logic:** `Force = (Target - Current) * Stiffness - (Velocity * Damping)`
*   **Behavior:** When a Bass kick hits:
    1.  `targetRotX` spikes to 35 degrees.
    2.  The Spring pulls `masterRotX` towards 35.
    3.  It overshoots slightly (bounce) and settles back to 0.
*   **Result:** The camera "Headbangs" perfectly in sync with the audio.

### 3.2 2.5D Rendering
**Function:** `renderCharacterCanvas`
*   We simulate 3D depth on 2D sprites using `ctx.transform` and `ctx.scale`:
    *   **Page Turn:** We scale the X-axis by `cos(rotationY)`. This looks like a flat card turning in 3D.
    *   **Squash & Stretch:** On beat impact, we scale Y by `0.85` and X by `1.15`. This gives the character "weight" and elasticity.

---

## 4. THE WORLD: HOLOGRAPHIC VISUALIZER (`Visualizer/HolographicVisualizer.ts`)

A custom WebGL Raymarching engine that renders the background.

### 4.1 The Shader (`FRAGMENT_SHADER`)
*   **Technique:** KIFS (Kaleidoscopic Iterated Function System). It folds 3D space recursively to create fractals.
*   **Uniforms:**
    *   `u_audioBass`: Modulates the `breathing` variable, expanding the fractal.
    *   `u_audioHigh`: Modulates the `twist` rotation.
    *   `u_cameraRot`: This is CRITICAL. It receives the `masterRot` from the Physics engine (Step 4), ensuring the background rotates *with* the character's headbang.

### 4.2 The "Quantum Foam"
*   **Idle State:** High density (`2.5`), low speed. Looks like thick fog.
*   **Active State:** When the user interacts or music plays, density drops (`0.5`), revealing the sharp fractal geometry.

---

## 5. APP STATE & ARCHITECTURE (`App.tsx`, `GlobalBackground.tsx`)

### 5.1 The Global Event Bus
**Why:** React prop drilling is too slow for 60FPS visualizer updates (like mouse movement).
**Solution:** `window.dispatchEvent('ui-interaction')`
*   The `GlobalBackground` component listens for these raw events to update the WebGL uniforms instantly, bypassing the React render cycle.

### 5.2 Client-Side Export
**Function:** `Step4Preview -> startRecording`
*   **Tech:** `MediaRecorder` API.
*   **Process:**
    1.  We draw the WebGL background to a hidden canvas.
    2.  We draw the Character composite on top.
    3.  We capture the stream (`captureStream(60)`).
    4.  We mux in the Audio Track.
    5.  We output a `.webm` file.
*   **Benefit:** $0 Server Cost. Infinite scalability.

---

## 6. SUMMARY OF CHANGES (The "Fix")

1.  **Grid Alignment:** Moved from "Smart Crop" -> **"Stretch-to-Fit" + "10% Safety Crop"**. This fixed the limbs getting cut off.
2.  **Scale:** Enforced **75% Scale** in Gemini prompts. This fixed the centering issues.
3.  **Timing:** Moved from "Linear Interpolation" -> **"Audio-Gated Hard Cuts"**. This fixed the "mushy/lazy" animation feel.
4.  **Physics:** Added **Spring Dynamics** to the Camera. This makes the static images feel like a 3D experience.

This architecture represents a shift from "Generative Chaos" to "Generative Structure."
